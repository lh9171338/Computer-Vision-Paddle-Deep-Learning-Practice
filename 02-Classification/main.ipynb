{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 实验名称：桃子分类模型的搭建与训练"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.实验目标\n",
    "\n",
    "本实验主要讲解：用paddlepaddle深度学习框架搭建桃子分类模型，并完成训练和测试的全过程。\n",
    "\n",
    "完成此实验后，可以掌握的能力有：\n",
    "\n",
    "> - 掌握paddlepaddle深度学习框架的使用方法；\n",
    "> - 掌握如何用paddlepaddle深度学习框架搭建 桃子分类模型；\n",
    "> - 掌握如何完成模型的训练、评估、保存、预测等深度学习工作过程；\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.实验背景介绍\n",
    "\n",
    "图像分类是计算机视觉的基础，也是其他计算机复杂任务的基础。深度学习技术发展到现在，诞生了许多优秀的图像分类算法。本次桃子分拣，我们就使用其中的典型算法代表**resnet**。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 使用paddlepaddle框架一般流程介绍\n",
    "\n",
    "\n",
    "\n",
    "如今，paddlepaddle已经推出了2.0版本，在2.0版本中，推出了高阶API，使得代码更简洁，变成更容易。  \n",
    "\n",
    "目前飞桨高层API由五个模块组成，分别是数据加载、模型组建、模型训练、模型可视化和高阶用法。如下图所示：\n",
    "\n",
    "<center><img src=\"https://ai-studio-static-online.cdn.bcebos.com/bf01393108dd46f4899e616148429cb7aca6a224fe3f44858b59a5ec69684756\" width=\"600\" hegiht=\"500\" ></center>\n",
    "<br></br>\n",
    "\n",
    "用paddlepaddle框架进行深度学习项目十分容易，按照一般流程即可完成深度学习项目（下图为项目实施一般流程）。该流程主要包含五大步骤分别为数据处理、模型设计、训练配置、训练过程和模型保存。在数据处理阶段主要是为模型准可用的数据，包括本地或者网络数据的收集与预处理。模型设计阶段就是深度学习项目中大家讨论最多的模型搭建，在这阶段关键就是网络结构的设计与实现，飞桨框架为开发者准备好了大量的经过工业验证的模型库和预训练模型方便开发者直接使用。在训练配置阶段开发者需要设定优化器类型和学习率衰减等参数，同时还需要指定使用GPU还是CPU完成计算。在训练过程阶段，就是框架真实运行计算过程的阶段。在该阶段，飞桨框架不断的完成正向传播、反向传播和梯度下降的过程。最后是模型保存，当模型达到预定指标或者达到预定的训练次数后，开发者可以将“训练好”的模型保存起来用以下次训练或者用以部署。\n",
    "\n",
    "<center><img src=\"https://ai-studio-static-online.cdn.bcebos.com/7be7279f57eb4c4e940fda61ffc46c2417a84ec2f3d24e12b2b28a00b1215af6\" width=\"800\" hegiht=\"500\" ></center>\n",
    "<center>用paddlepaddle框架进行深度学习项目流程</center>\n",
    "<br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 实验内容\n",
    "\n",
    "### 4.1 数据集介绍\n",
    "\n",
    "本次实验我们使用的数据集是四个种类桃子，这些桃子被分在四个文件夹中，每一个文件夹的名字就对应着一类桃子。\n",
    "\n",
    "<center><img src=\"https://ai-studio-static-online.cdn.bcebos.com/21d7a193d1b9455e93ed3898ea66cfbaad52fb9432c346dd93ab475511302b6c\" width=\"800\" hegiht=\"500\" ></center>\n",
    "<center>桃子数据集</center>\n",
    "<br></br>\n",
    "\n",
    "用我们自己的眼睛来观察，好像这些桃子是按照 大小、颜色 来划分的四类；究竟是不是这样呢？等做完了这个实验，深度学习模型自己就能判断出来是按照什么来划分了。\n",
    "\n",
    "本次实验，已经为大家提供好了数据集，数据集存储在 <font face=\"黑体\" color=red size=3>“data/enhancement/”</font> 文件夹下。图片分为2个文件夹，一个是训练集一个是测试集。每个文件夹中有4个分类：R0,B1,M2,S3。\n",
    "桃子分拣原数据集，包含两个文件夹：“train”、“test”  \n",
    "每个文件夹下有：“B1”、“M2”、“R0”、“S3”  \n",
    "训练集：  \n",
    "    train_B1:1601张图片  \n",
    "    train_M2:1800张图片  \n",
    "    train_R0:1601张图片  \n",
    "    train_S3:1635张图片  \n",
    "测试集：  \n",
    "    test_B1:16张图片  \n",
    "    test_M2:18张图片  \n",
    "    test_R0:18张图片  \n",
    "    test_S3:15张图片  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 数据解压。如果已经解压过一次了，就将该段代码注释掉\n",
    "# !unzip /home/aistudio/data/data103593/data.zip -d /home/aistudio/data/enhancement_data/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 实验文件介绍\n",
    "\n",
    "本次实验文件结构如下：\n",
    "\n",
    "本次实验的代码、数据集 都已经为大家准备好，目录结构如下图所示：\n",
    "\n",
    "<center><img src=\"https://ai-studio-static-online.cdn.bcebos.com/46b61b07e6124de3ab736dee5714554be25ddc4eb8e642489a239115c86197b5\" width=\"800\" hegiht=\"500\" ></center>\n",
    "<center>本次实验文件结构</center>\n",
    "<br></br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2  导入实验需要的库\n",
    "\n",
    "实验第一步，需要导入相关的库，最主要的是如下几个：\n",
    "\n",
    "> - os ： OS模块提供了非常丰富的方法用来处理文件和目录。\n",
    "> - sys：sys模块提供了一系列有关Python运行环境的变量和函数。\n",
    "> - shutil:用于文件拷贝的模块 \n",
    "> - numpy：numpy 是 Python 语言的一个扩展程序库，支持大量的维度数组与矩阵运算，此外也针对数组运算提供大量的数学函数库。\n",
    "> - random：Python中的random模块用于生成随机数。\n",
    "> - paddle.vision.datasets：该模块包含数据加载的相关函数，比如可以用来加载常用的数据集等，如mnist。\n",
    "> - paddle.vision.transforms:该模块包含对图像进行转换的函数，比如把HWC格式的图片，转变成CHW模式的输入张量。也包含飞桨框架对于图像预处理的方式，可以快速完成常见的图像预处理，如调整色调、对比度，图像大小等；\n",
    "> - paddle.io.Dataset:该模块包含了飞桨框架数据加载方式，可以“一键”完成数据的批加载与异步加载。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#os ： OS模块提供了非常丰富的方法用来处理文件和目录。\n",
    "#sys：sys模块提供了一系列有关Python运行环境的变量和函数。\n",
    "#shutil:用于文件拷贝的模块 \n",
    "#numpy：numpy 是 Python 语言的一个扩展程序库，支持大量的维度数组与矩阵运算，此外也针对数组运算提供大量的数学函数库。\n",
    "#random：Python中的random模块用于生成随机数。\n",
    "#paddle.vision.datasets：该模块包含数据加载的相关函数，比如可以用来加载常用的数据集等，如mnist。\n",
    "#paddle.vision.transforms:该模块包含对图像进行转换的函数，比如把HWC格式的图片，转变成CHW模式的输入张量。也包含飞桨框架对于图像预处理的方式，可以快速完成常见的图像预处理，如调整色调、对比度，图像大小等；\n",
    "#paddle.io.Dataset:高模块包含了飞桨框架数据加载方式，可以“一键”完成数据的批加载与异步加载。\n",
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "import numpy as np\n",
    "import paddle\n",
    "import random\n",
    "from paddle.io import Dataset, DataLoader\n",
    "from paddle.vision.datasets import DatasetFolder, ImageFolder\n",
    "from paddle.vision import transforms as T\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 数据集准备\n",
    "\n",
    "本次实验，已经为大家提供好了数据集，数据集存储在 <font face=\"黑体\" color=red size=3>“data/enhancement/”</font> 文件夹下。\n",
    "\n",
    "本次实验的数据预处理包括：\n",
    "\n",
    "> 1.生成txt文件  \n",
    "> 2.拆分训练集、验证集\n",
    "\n",
    "#### 4.3.1 生成txt文件\n",
    "\n",
    "为什么要生成txt文件呢？我们看到，在数据集中，每一个文件夹对应一个类别；但是并没有一个txt 文件来指定标签（label）；于是我们首先要生成txt文件；\n",
    "\n",
    "为了代码的整齐和简洁，我们把数据集路径等参数配置在一个全局变量**train_parameters**中。其解释如下：\n",
    "\n",
    "> - 'train_data_dir'是提供的经增强后的原始训练集；\n",
    "> - 'test_image_dir'是提供的原始测试集；\n",
    "> - 'train_image_dir'和'eval_image_dir'是由原始训练集经拆分后生成的实际训练集和验证集\n",
    "> - 'train_list_dir'和'test_list_dir'是生成的txt文件路径\n",
    "> - 'saved_model' 存放训练结果的文件夹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "参数配置：\n",
    "'train_data_dir'是提供的经增强后的原始训练集；\n",
    "'test_image_dir'是提供的原始测试集；\n",
    "'train_image_dir'和'eval_image_dir'是由原始训练集经拆分后生成的实际训练集和验证集\n",
    "'train_list_dir'和'test_list_dir'是生成的txt文件路径\n",
    "'saved_model' 存放训练结果的文件夹\n",
    "'''\n",
    "train_parameters = {          \n",
    "    'train_image_dir': './data/splitted_training_data/train_images',\n",
    "    'eval_image_dir': './data/splitted_training_data/eval_images',\n",
    "    'test_image_dir': './data/enhancement_data/test',\n",
    "    'train_data_dir':'./data/enhancement_data/train',\n",
    "    'train_list_dir':'./data/enhancement_data/train.txt',\n",
    "    'test_list_dir':'./data/enhancement_data/test.txt',  \n",
    "    'saved_model':'./saved_model/'\n",
    "}\n",
    "\n",
    "#数据集的4个类别标签\n",
    "labels = ['R0', 'B1', 'M2', 'S3']\n",
    "labels.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#准备生成训练集文件名、标签名的txt文件\n",
    "write_file_name = train_parameters[ 'train_list_dir']\n",
    "\n",
    "#以写方式打开write_file_name文件\n",
    "with open(write_file_name, \"w\") as write_file:\n",
    "    #针对不同的分类标签分别录入\n",
    "    for label in labels:\n",
    "        #建立空列表，用于保存图片名\n",
    "        file_list = [] \n",
    "        #用于找到该标签路径下的所有图片.\n",
    "        train_txt_dir = train_parameters[ 'train_data_dir']+'/'+label+'/'     \n",
    "\n",
    "        for file_name in os.listdir(train_txt_dir):\n",
    "            dir_name = label        \n",
    "            temp_line = dir_name + '/' + file_name + '\\t' + label + '\\n'    # 例如：\"B1/101.png\tB1\"\n",
    "            write_file.write(temp_line)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#准备生成测试集文件名、标签名的txt文件\n",
    "write_file_name = train_parameters[ 'test_list_dir']\n",
    "\n",
    "#以写方式打开write_file_name文件\n",
    "with open(write_file_name, \"w\") as write_file:\n",
    "    #针对不同的分类标签分别录入\n",
    "    for label in labels:\n",
    "        #建立空列表，用于保存图片名\n",
    "        file_list = [] \n",
    "        #用于找到该标签路径下的所有图片.\n",
    "        train_txt_dir = train_parameters[ 'test_image_dir']+'/'+label+'/'     \n",
    "\n",
    "        for file_name in os.listdir(train_txt_dir):\n",
    "            dir_name = label        \n",
    "            temp_line = dir_name + '/' + file_name + '\\t' + label + '\\n'    # 例如：\"B1/101.png\tB1\"\n",
    "            write_file.write(temp_line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以上步骤操作完之后，就会在 data/enhancement_data/目录下生成 train.txt   test.txt两个文件。\n",
    "\n",
    "<center><img src=\"https://ai-studio-static-online.cdn.bcebos.com/073480ede04b406cba32b9e621db79e0fcc869adea22405bad63d38b8cc91426\" width=\"500\" hegiht=\"500\" ></center>\n",
    "<br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3.2  划分训练集和验证集\n",
    "\n",
    "> - 我们已经有了训练集、测试集；最好还要把训练集再次拆分，从训练集中拆分出来一个验证集。  \n",
    "> - 这样，我们训练的时候，就可以用验证集来验证我们的模型训练效果，通过实时的观察训练效果，便于我们及时的调参。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#判断splitted_training_data文件夹是否存在，如果不存在就新建一个\n",
    "if not os.path.exists('data/splitted_training_data'):\n",
    "    os.makedirs('data/splitted_training_data')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating training and eval images\r\n",
      "划分训练集和验证集完成！\r\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#定义一个函数，来拆分训练集、验证集\n",
    "def create_train_eval():\n",
    "    '''\n",
    "    划分训练集和验证集\n",
    "    '''\n",
    "    train_dir = train_parameters['train_image_dir']\n",
    "    eval_dir = train_parameters['eval_image_dir']\n",
    "    train_list_path = train_parameters['train_list_dir']  \n",
    "    train_data_dir = train_parameters[ 'train_data_dir'] \n",
    "    \n",
    "    print('creating training and eval images')\n",
    "    #如果文件夹不存在，建立相应的文件夹\n",
    "    if not os.path.exists(train_dir):\n",
    "        os.mkdir(train_dir)\n",
    "    if not os.path.exists(eval_dir):\n",
    "        os.mkdir(eval_dir) \n",
    "\n",
    "    #打开txt文件，分割数据\n",
    "    file_name = train_list_path\n",
    "    f = open(file_name, 'r') \n",
    "    #按行读取数据\n",
    "    lines = f.readlines()\n",
    "    f.close()\n",
    "        \n",
    "    for i in range(len(lines)):\n",
    "        #将每行数据按照空格分割成2部分，并取第一部分的路径名和图像文件名，例如:R0/1.png\n",
    "        img_path = lines[i].split('\\t')[0] \n",
    "        #取第二部分的标签，例如:R0\n",
    "        class_label = lines[i].split('\\t')[1].strip('\\n')\n",
    "        # 每8张图片取一个做验证数据,其他用于训练\n",
    "        if i % 8 == 0:\n",
    "            #把目录和文件名合成一个路径\n",
    "            eval_target_dir = os.path.join(eval_dir, class_label) \n",
    "            #将总的文件路径与当前图像的文件名合到一起，实际就是得到训练集图像所在的文件夹下的图像名   \n",
    "            eval_img_path = os.path.join(train_data_dir, img_path)\n",
    "            if not os.path.exists(eval_target_dir):\n",
    "                    os.mkdir(eval_target_dir)  \n",
    "            #将图片复制到验证集指定标签的文件夹下      \n",
    "            shutil.copy(eval_img_path, eval_target_dir) \n",
    "        else:           \n",
    "            train_target_dir = os.path.join(train_dir, class_label)                                 \n",
    "            train_img_path = os.path.join(train_data_dir, img_path)\n",
    "            if not os.path.exists(train_target_dir):\n",
    "                os.mkdir(train_target_dir)\n",
    "            shutil.copy(train_img_path, train_target_dir) \n",
    "    print ('划分训练集和验证集完成！')\n",
    "\n",
    "\n",
    "# 制作数据集，如果已经做好了，就请将代码注释掉\n",
    "create_train_eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "运行完上面的代码，就完成了训练集、验证集的拆分。拆分放在 ./data/splitted_training_data/  目录下：\n",
    "\n",
    "<center><img src=\"https://ai-studio-static-online.cdn.bcebos.com/f1d018b859ed4dfb947625e10c4e04e129459cfaa8744ec993ec0b8b59cdcc94\" width=\"500\" hegiht=\"500\" ></center>\n",
    "<br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5  自定义数据集类\n",
    "\n",
    "飞桨框架将一些我们常用的数据集做成了API，对用户开放，对应API为paddle.vision.datasets与paddle.text.datasets。我们使用的时候可以直接调用这些API就可以完成数据集的下载和使用。这些集成好的数据集有：\n",
    "\n",
    "> - <font face=\"黑体\" color=red size=3>视觉相关数据集： ['DatasetFolder', 'ImageFolder', 'MNIST', 'FashionMNIST', 'Flowers', 'Cifar10', 'Cifar100', 'VOC2012']</font> \n",
    "> - <font face=\"黑体\" color=red size=3>自然语言相关数据集： ['Conll05st', 'Imdb', 'Imikolov', 'Movielens', 'UCIHousing', 'WMT14', 'WMT16']\n",
    "</font>\n",
    "\n",
    "但是，在实际的使用场景中，我们往往需要用到自己的数据集。比如本次实验，我们就使用自己的桃子数据集。\n",
    "\n",
    "飞桨为用户提供了paddle.io.Dataset基类，让用户通过类的集成来快速实现数据集定义。\n",
    "\n",
    "PaddlePaddle对数据集的加载方式是：统一使用Dataset（数据集定义） + DataLoader（多进程数据集加载）。\n",
    "\n",
    "\n",
    "#### 数据集定义-Dataset\n",
    "> - 首先我们先进行数据集的定义 ；  \n",
    "> - 数据集定义主要是实现一个新的Dataset类，继承父类paddle.io.Dataset；  \n",
    "> - 然后实现父类中以下两个抽象方法，“__ getitem __ ”和 “__ len __”：  \n",
    "\n",
    "<center><img src=\"https://ai-studio-static-online.cdn.bcebos.com/1ffc401ddd7a49e69aaf5dc92314e9f3f4ec0054b63744e29e23b3b3de2b8a2c\" width=\"700\" hegiht=\"500\" ></center>\n",
    "<br></br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class PeachDataset(Dataset):\n",
    "    \"\"\"\n",
    "    步骤一：继承paddle.io.Dataset类\n",
    "    \"\"\"\n",
    "    def __init__(self, mode='train'):\n",
    "        \"\"\"\n",
    "        步骤二：实现构造函数，定义数据读取方式，划分训练、验证和测试数据集\n",
    "        \"\"\"\n",
    "        super(PeachDataset, self).__init__()\n",
    "        train_image_dir = train_parameters['train_image_dir']#训练集的路径\n",
    "        eval_image_dir = train_parameters['eval_image_dir']\n",
    "        test_image_dir = train_parameters['test_image_dir']        \n",
    "        \n",
    "        '''         ''' \n",
    "        #transform数据增强函数，这里仅对图片的打开方式进行了转换            \n",
    "        #这里用Transpose()将图片的打开方式(宽, 高, 通道数)更改为PaddlePaddle读取的方式是(通道数, 宽, 高)\n",
    "        mean = [127.5, 127.5, 127.5] # 归一化，均值\n",
    "        std = [127.5, 127.5, 127.5] # 归一化，标注差 \n",
    "        transform_train = T.Compose([T.ColorJitter(0.4, 0.4, 0.4, 0.4)\n",
    "                                     ,T.Resize(size=(224,224)) \n",
    "                                     ,T.Transpose()\n",
    "                                     ,T.Normalize(mean, std)\n",
    "                                    ])\n",
    "        transform_eval = T.Compose([T.Resize(size=(224,224)) \n",
    "                                    ,T.Transpose()\n",
    "                                    ,T.Normalize(mean, std)\n",
    "                                    ])\n",
    "        transform_test = T.Compose([T.Resize(size=(224,224)) \n",
    "                                    ,T.Transpose()\n",
    "                                    ,T.Normalize(mean, std)\n",
    "                                    ])\n",
    "        \n",
    "        '''         \n",
    "        # 参考API：https://www.paddlepaddle.org.cn/documentation/docs/zh/api/paddle/vision/Overview_cn.html#about-transforms\n",
    "        #这里用Transpose()将图片的打开方式(宽, 高, 通道数)更改为PaddlePaddle读取的方式是(通道数, 宽, 高)\n",
    "        # ColorJitter 随机调整图像的亮度，对比度，饱和度和色调。\n",
    "        # hflip 对输入图像进行水平翻转。        \n",
    "        # Normalize 归一化。mean = [127.5, 127.5, 127.5]，std = [127.5, 127.5, 127.5]\n",
    "        # RandomHorizontalFlip 基于概率来执行图片的水平翻转。\n",
    "        # RandomVerticalFlip 基于概率来执行图片的垂直翻转。\n",
    "        mean = [127.5, 127.5, 127.5] # 归一化，均值\n",
    "        std = [127.5, 127.5, 127.5] # 归一化，标注差 \n",
    "        transform_train = T.Compose([T.Resize(size=(224,224)), \n",
    "                                     T.Transpose(),                                \n",
    "                                     T.ColorJitter(0.4, 0.4, 0.4, 0.4),\n",
    "                                     T.RandomHorizontalFlip(prob=0.5,),\n",
    "                                     T.RandomVerticalFlip(prob=0.5,),\n",
    "                                     T.Normalize(mean, std)])\n",
    "        transform_eval = T.Compose([T.Resize(size=(224,224)), T.Transpose()])\n",
    "        transform_test = T.Compose([T.Resize(size=(224,224)), T.Transpose()])\n",
    "        ''' \n",
    "\n",
    "        #飞桨推荐使用 paddle.io.DataLoader 完成数据的加载，生成一个可以加载数据的迭代器\n",
    "        # 参考API:https://www.paddlepaddle.org.cn/documentation/docs/zh/api/paddle/io/DataLoader_cn.html#cn-api-fluid-io-dataloader\n",
    "        #加载训练集，train_data_folder 是一个迭代器\n",
    "        # 参考API：https://www.paddlepaddle.org.cn/documentation/docs/zh/api/paddle/vision/datasets/DatasetFolder_cn.html#datasetfolder\n",
    "        train_data_folder = DatasetFolder(train_image_dir, transform=transform_train)\n",
    "        #加载验证集，eval_data_folder 是一个迭代器\n",
    "        eval_data_folder = DatasetFolder(eval_image_dir, transform=transform_eval)\n",
    "        #加载测试集，test_data_folder 是一个迭代器\n",
    "        test_data_folder = DatasetFolder(test_image_dir, transform=transform_test)\n",
    "        self.mode = mode\n",
    "        if self.mode  == 'train':\n",
    "            self.data = train_data_folder\n",
    "        elif self.mode  == 'eval':\n",
    "            self.data = eval_data_folder\n",
    "        elif self.mode  == 'test':\n",
    "            self.data = test_data_folder\n",
    "\n",
    "    # 每次迭代时返回数据和对应的标签\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        步骤三：实现__getitem__方法，定义指定index时如何获取数据，并返回单条数据（训练数据，对应的标签）\n",
    "        \"\"\"\n",
    "        data = np.array(self.data[index][0]).astype('float32')\n",
    "\n",
    "        label = np.array([self.data[index][1]]).astype('int64')\n",
    "\n",
    "        return data, label\n",
    "\n",
    "    # 返回整个数据集的总数\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        步骤四：实现__len__方法，返回数据集总数目\n",
    "        \"\"\"\n",
    "        return len(self.data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#用自定义的PeachDataset类，加载自己的数据集\n",
    "train_dataset = PeachDataset(mode='train')\n",
    "val_dataset = PeachDataset(mode='eval')\n",
    "test_dataset = PeachDataset(mode='test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 数据集加载-DataLoader\n",
    "DataLoader 返回一个迭代器，迭代器返回的数据中的每个元素都是一个Tensor，其调用方法如下：\n",
    "\n",
    "```python\n",
    "class paddle.io.DataLoader(dataset, feed_list=None, places=None, return_list=False, batch_sampler=None, batch_size=1, shuffle=False, drop_last=False, collate_fn=None, num_workers=0, use_buffer_reader=True, use_shared_memory=True, timeout=0, worker_init_fn=None)\n",
    "```\n",
    "DataLoader 迭代一次给定的 dataset（顺序由 batch_sampler 给定）  \n",
    "DataLoader支持**单进程**和**多进程**的数据加载方式，当 num_workers 大于0时，将使用多进程方式异步加载数据。\n",
    "\n",
    "> 详细介绍 https://www.paddlepaddle.org.cn/documentation/docs/zh/api/paddle/io/DataLoader_cn.html\n",
    "\n",
    "\n",
    "下面的代码用来展示如何使用 DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opencv 版本号为：4.1.1\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/matplotlib/__init__.py:107: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\r\n",
      "  from collections import MutableMapping\r\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/matplotlib/rcsetup.py:20: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\r\n",
      "  from collections import Iterable, Mapping\r\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/matplotlib/colors.py:53: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\r\n",
      "  from collections import Sized\r\n"
     ]
    }
   ],
   "source": [
    "# DataLoader 示例代码\n",
    "\n",
    "# 加载库\n",
    "import cv2 as cv #使用 OpenCV\n",
    "print(\"opencv 版本号为：\" + cv.__version__) #查看版本号\n",
    "# 事实上在使用 OpenCV之前应该安装该类库，但是由于使用了 AI-Studio，所以系统已经替开发者预先安装好了： opencv-python 4.1.1.26       \n",
    "from matplotlib import pyplot as plt #在该页面画图\n",
    "%matplotlib inline \n",
    "\n",
    "# 构造一个 DataLoader\n",
    "test_loader = DataLoader(test_dataset,\n",
    "                    batch_size=2,\n",
    "                    shuffle=True,\n",
    "                    drop_last=True,\n",
    "                    num_workers=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mini_batch 的类型为：<class 'list'>\r\n",
      "mini_batch 的大小为：2\r\n",
      "(3, 224, 224)\r\n",
      "(3, 224, 224)\r\n"
     ]
    }
   ],
   "source": [
    "# 使用 DataLoader 来遍历数据集\n",
    "for mini_batch in test_loader(): # 从 DataLoader 中获取 mini_batch \n",
    "    print(\"mini_batch 的类型为：\" + str(type(mini_batch)))\n",
    "    pic_list = mini_batch[0] #图片数据\n",
    "    label_list = mini_batch[1] #标记\n",
    "    print(\"mini_batch 的大小为：\" + str(len(pic_list)))\n",
    "\n",
    "    # 将图片显示转化为 numpy 格式，并且将内部的数字设置为 整数类型\n",
    "    pic_1 = pic_list[0]\n",
    "    pic_2 = pic_list[1]\n",
    "    arr1 = np.asarray(pic_1, dtype=np.float64) \n",
    "    print(arr1.shape)\n",
    "    arr2 = np.asarray(pic_2, dtype=np.float64)    \n",
    "    print(arr2.shape)\n",
    "\n",
    "    break #由于是示例，所以仅拿出第一个 mini_batch\n",
    "    \n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/matplotlib/cbook/__init__.py:2349: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\r\n",
      "  if isinstance(obj, collections.Iterator):\r\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/matplotlib/cbook/__init__.py:2366: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\r\n",
      "  return list(data) if isinstance(data, collections.MappingView) else data\r\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\r\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fb4678d8350>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 把获取到的图片数据展示出来\n",
    "r = arr1[0]\n",
    "g = arr1[1]\n",
    "b = arr1[2]\n",
    "img = cv.merge([r,g,b])\n",
    "\n",
    "plt.imshow(img)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如上图所示，这时候取得的图片并不是原始图片的样子。那是因为在 PeachDataset 类中，对图片数据使用了 transform 方法，也就是对图片做了一些变化。为了说明这一点，可以使用下面的方法作对比。\n",
    "\n",
    "下图为已经发生变化图片：\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/68679a450e8c4df98fac8ccd09eb27029f771450fe0546f7834e73170c4c135b)\n",
    "\n",
    "\n",
    "为了对比说明请修改 PeachDataset 类中的代码，加入一个注释符号，代码如下：  \n",
    "这样做的目的是，既可以改变图片的大小而且符合paddle的要求，又可以避免产生归一化引起的数据变动。  \n",
    "```python\n",
    "transform_test = T.Compose([\n",
    "                    T.Resize(size=(224,224)) \n",
    "                   ,T.Transpose()\n",
    "                   #,T.Normalize(mean, std)\n",
    "                   ])\n",
    "```       \n",
    "\n",
    "修改完该代码后，请打开下面的代码的注释，重启执行器，点击右上角的 “运行->运行当前选中及之前的所有cell”\n",
    "  \n",
    "就可以看到原始数据集中的图片，如下图所示：\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/e2b2b7868b124b6c9478cebd1f0c53024457229eef1b4c75a0c1676dd2489c41)\n",
    "\n",
    "查看完数据后，请不要忘记，打开 PeachDataset 类中的注释。和加入下方代码的注释。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "# 把获取到的图片数据展示出来\n",
    "arr1 = arr1 / 255 # 把每一个像素都变到 0-1 之间\n",
    "r = arr1[0]\n",
    "g = arr1[1]\n",
    "b = arr1[2]\n",
    "img = cv.merge([r,g,b])\n",
    "\n",
    "plt.imshow(img)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.6  搭建分类模型\n",
    "\n",
    "接下来，我们就要搭建一个图像分类模型，用这个模型可以实现桃子数据集的分类。\n",
    "\n",
    "怎么搭建分类模型呢？\n",
    "> - 我们可以按照自己的想法搭建DNN网络模型，或者CNN网络模型，或者其他网络模型，但是这对我们的算法研究能力要求很高；\n",
    "> - 我们可以使用已经成熟的、经典的网络模型，比如VGG、ResNet等；用paddle框架来搭建这些模型，来为我们所用。\n",
    "\n",
    "本次实验，我们就采用50层的残差网络ResNet作为我们的分类模型。\n",
    "\n",
    "并且，本次实验，为了增加我们的模型效果，我们还是使用了迁移学习方法。那么为什么要用迁移学习呢？怎么使用迁移学习呢？\n",
    "\n",
    "### 4.6.1 迁移学习\n",
    "\n",
    "现实的工程开发中，很少有人从零开始训练一个完整的神经网络。\n",
    "\n",
    "<font face=\"黑体\" color=red size=3>为什么？</font>\n",
    "\n",
    "因为一般我们的数据集都不是很大，所以训练出的模型泛化能力往往不强。且训练非常耗时。\n",
    "\n",
    "<font face=\"黑体\" color=red size=3>怎么做？</font>\n",
    "\n",
    "常用的方法是找到一个很大的公有数据集（比如ImageNet，包含了120万张图片和1000个类别），在这个数据集上先训练好一个神经网络模型A（这个A一般别人已经训练好了），然后将这个A作为一个起始点，经过微调，再训练我们自己的数据集。这个A也叫做 **“预训练模型”**。\n",
    "\n",
    "这就是 **迁移学习** 的一种方法，也叫做 **fine tune**。\n",
    "\n",
    "那么fine tune的理论依据是什么？也即是：为什么我们可以在别人训练好的模型的基础上进行微调？这就要从卷积神经网络的结构原理上进行分析。\n",
    "\n",
    "> - 对于卷积网络来说：前面几层都学习到的是通用的特征（generalfeature），比如图像的边缘；随着网络层次的加深，后面的网络更偏重于学习特定的特征（specific feature），例如身体部位、面部和其他组合性特征。\n",
    "> - 最后的全连接层通常被认为是捕获了与解决相应任务相关的信息，例如 AlexNet 的全连接层可以指出提取的这些特征属于1000 类物体中的哪一类。\n",
    "> - 比如在人脸识别过程中，初级的若干层卷积会提取到直线、曲线等通用特征；中间若干层卷积会进一步学习到眼睛、鼻子等特定部位，高层卷积则可以学习到组合特征，从而判断出这是一张人脸图像。\n",
    "> -卷积神经网络的这种特性，就是我们的fine tune理论依据。\n",
    "\n",
    "可能有同学会问：那为什么我们不直接用别人在大数据集（比如ImageNet）上训练好的模型，而是还要微调呢？\n",
    "\n",
    "> - 因为别人训练好的模型，可能并不是完全适用于我们自己的任务。可能别人的网络能做比我们的任务更多的事情；可能别人的网络比较复杂，我们的任务比较简单。\n",
    "> -举一个例子，假如我们想训练一个猫狗图像二分类的网络，我们首先会想到直接使用别人在 ImageNet上训练好的网络模型。但是 ImageNet 有 1000 个类别，而我们只需要2 个类别。此时，就需要针对我们自己的任务，来进行微调了，比如可以固定原始网络的相关层，修改网络的输出层，以使结果更符合我们的需要。\n",
    "\n",
    "\n",
    "在PaddlePaddle2.0中，使用预训练模型只需要设定模型参数pretained=True。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.6.2 搭建模型\n",
    "\n",
    "使用飞桨，很便利的一点是：飞桨框架内置了许多模型，真正的一行代码实现深度学习模型。\n",
    "\n",
    "目前，飞桨框架内置的模型都是CV领域的模型，在paddle.vision.models目录下，具体包含如下的模型：\n",
    "\n",
    "\n",
    "<font face=\"黑体\" color=red size=3>飞桨框架内置模型： ['ResNet', 'resnet18', 'resnet34', 'resnet50', 'resnet101', 'resnet152', 'VGG', 'vgg11', 'vgg13', 'vgg16', 'vgg19', 'MobileNetV1', 'mobilenet_v1', 'MobileNetV2', 'mobilenet_v2', 'LeNet']\n",
    "</font>\n",
    "\n",
    "比如我们本次使用的resnet50，就已经有内置模型了。  \n",
    "\n",
    "<center><img src=\"https://ai-studio-static-online.cdn.bcebos.com/811e72cbe4c14ec8b83f41ce222bace5f7c5a8d69a084d668a8cd716c6f1360c\" width=\"700\" hegiht=\"500\" ></center>\n",
    "<br></br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 69183/69183 [00:01<00:00, 47292.60it/s]\r\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dygraph/layers.py:1301: UserWarning: Skip loading for fc.weight. fc.weight receives a shape [512, 1000], but the expected shape is [512, 4].\r\n",
      "  warnings.warn((\"Skip loading for {}. \".format(key) + str(err)))\r\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dygraph/layers.py:1301: UserWarning: Skip loading for fc.bias. fc.bias receives a shape [1000], but the expected shape is [4].\r\n",
      "  warnings.warn((\"Skip loading for {}. \".format(key) + str(err)))\r\n"
     ]
    }
   ],
   "source": [
    "# 使用内置的模型,这边可以选择多种不同网络，这里选了resnet50网络\n",
    "#pretrained (bool，可选) - 是否加载在imagenet数据集上的预训练权重\n",
    "model = paddle.vision.models.resnet18(pretrained=True, num_classes=4)    \n",
    "\n",
    "#尝试不同的网络结构：MobileNetV2\n",
    "# MobileNetV2参考文档：https://www.paddlepaddle.org.cn/documentation/docs/zh/api/paddle/vision/models/MobileNetV2_cn.html\n",
    "# model = paddle.vision.models.mobilenet_v2(pretrained=True, num_classes=4)    \n",
    "\n",
    "#使用paddle.Model完成模型的封装，将网络结构组合成一个可快速使用高层API进行训练和预测的类。\n",
    "model = paddle.Model(model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用 model.summary 观察网络情况\n",
    "> 参考文档： https://github.com/PaddlePaddle/Paddle/blob/release/2.1/python/paddle/hapi/model.py#L883\n",
    "\n",
    "API 文档写的和真实代码之间稍有不同\n",
    "\n",
    "```python\n",
    "# 以下为源代码\n",
    "def summary(self, input_size=None, dtype=None):\n",
    "        \"\"\"Prints a string summary of the network.\n",
    "        Args:\n",
    "            input_size (tuple|InputSpec|list[tuple|InputSpec], optional): size of input tensor. \n",
    "                    if not set, input_size will get from ``self._inputs`` if network only have \n",
    "                    one input, input_size can be tuple or InputSpec. if model have multiple \n",
    "                    input, input_size must be a list which contain every input's shape. \n",
    "                    Default: None.\n",
    "            dtypes (str, optional): if dtypes is None, 'float32' will be used, Default: None.\n",
    "        Returns:\n",
    "            Dict: a summary of the network including total params and total trainable params.\n",
    "        Examples:\n",
    "            .. code-block:: python\n",
    "              import paddle\n",
    "              from paddle.static import InputSpec\n",
    "           \n",
    "              input = InputSpec([None, 1, 28, 28], 'float32', 'image')\n",
    "              label = InputSpec([None, 1], 'int64', 'label')\n",
    "           \n",
    "              model = paddle.Model(paddle.vision.models.LeNet(),\n",
    "                  input, label)\n",
    "              optim = paddle.optimizer.Adam(\n",
    "                  learning_rate=0.001, parameters=model.parameters())\n",
    "              model.prepare(\n",
    "                  optim,\n",
    "                  paddle.nn.CrossEntropyLoss())\n",
    "              params_info = model.summary()\n",
    "              print(params_info)\n",
    "        \"\"\"\n",
    "        assert (input_size is not None or self._inputs is not None\n",
    "                ), \"'input_size' or 'self._input' must be set\"\n",
    "        if input_size is not None:\n",
    "            _input_size = input_size\n",
    "        else:\n",
    "            _input_size = self._inputs\n",
    "        return summary(self.network, _input_size, dtype)\n",
    "```\n",
    "参数：\n",
    "- input_size (tuple|InputSpec|list) - 输入张量的大小。如果网络只有一个输入，那么该值需要设定为tuple或InputSpec。如果模型有多个输入。那么该值需要设定为list[tuple|InputSpec]，包含每个输入的shape。如果该值没有设置，会将 self._inputs 作为输入。默认值：None。\n",
    "- dtypes (str，可选) - 输入张量的数据类型，如果没有给定，默认使用 float32 类型。默认值：None。\n",
    "\n",
    "返回：字典。包含网络全部参数的大小和全部可训练参数的大小。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------\r\n",
      "   Layer (type)         Input Shape          Output Shape         Param #    \r\n",
      "===============================================================================\r\n",
      "     Conv2D-1        [[1, 3, 224, 224]]   [1, 64, 112, 112]        9,408     \r\n",
      "   BatchNorm2D-1    [[1, 64, 112, 112]]   [1, 64, 112, 112]         256      \r\n",
      "      ReLU-1        [[1, 64, 112, 112]]   [1, 64, 112, 112]          0       \r\n",
      "    MaxPool2D-1     [[1, 64, 112, 112]]    [1, 64, 56, 56]           0       \r\n",
      "     Conv2D-2        [[1, 64, 56, 56]]     [1, 64, 56, 56]        36,864     \r\n",
      "   BatchNorm2D-2     [[1, 64, 56, 56]]     [1, 64, 56, 56]          256      \r\n",
      "      ReLU-2         [[1, 64, 56, 56]]     [1, 64, 56, 56]           0       \r\n",
      "     Conv2D-3        [[1, 64, 56, 56]]     [1, 64, 56, 56]        36,864     \r\n",
      "   BatchNorm2D-3     [[1, 64, 56, 56]]     [1, 64, 56, 56]          256      \r\n",
      "   BasicBlock-1      [[1, 64, 56, 56]]     [1, 64, 56, 56]           0       \r\n",
      "     Conv2D-4        [[1, 64, 56, 56]]     [1, 64, 56, 56]        36,864     \r\n",
      "   BatchNorm2D-4     [[1, 64, 56, 56]]     [1, 64, 56, 56]          256      \r\n",
      "      ReLU-3         [[1, 64, 56, 56]]     [1, 64, 56, 56]           0       \r\n",
      "     Conv2D-5        [[1, 64, 56, 56]]     [1, 64, 56, 56]        36,864     \r\n",
      "   BatchNorm2D-5     [[1, 64, 56, 56]]     [1, 64, 56, 56]          256      \r\n",
      "   BasicBlock-2      [[1, 64, 56, 56]]     [1, 64, 56, 56]           0       \r\n",
      "     Conv2D-7        [[1, 64, 56, 56]]     [1, 128, 28, 28]       73,728     \r\n",
      "   BatchNorm2D-7     [[1, 128, 28, 28]]    [1, 128, 28, 28]         512      \r\n",
      "      ReLU-4         [[1, 128, 28, 28]]    [1, 128, 28, 28]          0       \r\n",
      "     Conv2D-8        [[1, 128, 28, 28]]    [1, 128, 28, 28]       147,456    \r\n",
      "   BatchNorm2D-8     [[1, 128, 28, 28]]    [1, 128, 28, 28]         512      \r\n",
      "     Conv2D-6        [[1, 64, 56, 56]]     [1, 128, 28, 28]        8,192     \r\n",
      "   BatchNorm2D-6     [[1, 128, 28, 28]]    [1, 128, 28, 28]         512      \r\n",
      "   BasicBlock-3      [[1, 64, 56, 56]]     [1, 128, 28, 28]          0       \r\n",
      "     Conv2D-9        [[1, 128, 28, 28]]    [1, 128, 28, 28]       147,456    \r\n",
      "   BatchNorm2D-9     [[1, 128, 28, 28]]    [1, 128, 28, 28]         512      \r\n",
      "      ReLU-5         [[1, 128, 28, 28]]    [1, 128, 28, 28]          0       \r\n",
      "     Conv2D-10       [[1, 128, 28, 28]]    [1, 128, 28, 28]       147,456    \r\n",
      "  BatchNorm2D-10     [[1, 128, 28, 28]]    [1, 128, 28, 28]         512      \r\n",
      "   BasicBlock-4      [[1, 128, 28, 28]]    [1, 128, 28, 28]          0       \r\n",
      "     Conv2D-12       [[1, 128, 28, 28]]    [1, 256, 14, 14]       294,912    \r\n",
      "  BatchNorm2D-12     [[1, 256, 14, 14]]    [1, 256, 14, 14]        1,024     \r\n",
      "      ReLU-6         [[1, 256, 14, 14]]    [1, 256, 14, 14]          0       \r\n",
      "     Conv2D-13       [[1, 256, 14, 14]]    [1, 256, 14, 14]       589,824    \r\n",
      "  BatchNorm2D-13     [[1, 256, 14, 14]]    [1, 256, 14, 14]        1,024     \r\n",
      "     Conv2D-11       [[1, 128, 28, 28]]    [1, 256, 14, 14]       32,768     \r\n",
      "  BatchNorm2D-11     [[1, 256, 14, 14]]    [1, 256, 14, 14]        1,024     \r\n",
      "   BasicBlock-5      [[1, 128, 28, 28]]    [1, 256, 14, 14]          0       \r\n",
      "     Conv2D-14       [[1, 256, 14, 14]]    [1, 256, 14, 14]       589,824    \r\n",
      "  BatchNorm2D-14     [[1, 256, 14, 14]]    [1, 256, 14, 14]        1,024     \r\n",
      "      ReLU-7         [[1, 256, 14, 14]]    [1, 256, 14, 14]          0       \r\n",
      "     Conv2D-15       [[1, 256, 14, 14]]    [1, 256, 14, 14]       589,824    \r\n",
      "  BatchNorm2D-15     [[1, 256, 14, 14]]    [1, 256, 14, 14]        1,024     \r\n",
      "   BasicBlock-6      [[1, 256, 14, 14]]    [1, 256, 14, 14]          0       \r\n",
      "     Conv2D-17       [[1, 256, 14, 14]]     [1, 512, 7, 7]       1,179,648   \r\n",
      "  BatchNorm2D-17      [[1, 512, 7, 7]]      [1, 512, 7, 7]         2,048     \r\n",
      "      ReLU-8          [[1, 512, 7, 7]]      [1, 512, 7, 7]           0       \r\n",
      "     Conv2D-18        [[1, 512, 7, 7]]      [1, 512, 7, 7]       2,359,296   \r\n",
      "  BatchNorm2D-18      [[1, 512, 7, 7]]      [1, 512, 7, 7]         2,048     \r\n",
      "     Conv2D-16       [[1, 256, 14, 14]]     [1, 512, 7, 7]        131,072    \r\n",
      "  BatchNorm2D-16      [[1, 512, 7, 7]]      [1, 512, 7, 7]         2,048     \r\n",
      "   BasicBlock-7      [[1, 256, 14, 14]]     [1, 512, 7, 7]           0       \r\n",
      "     Conv2D-19        [[1, 512, 7, 7]]      [1, 512, 7, 7]       2,359,296   \r\n",
      "  BatchNorm2D-19      [[1, 512, 7, 7]]      [1, 512, 7, 7]         2,048     \r\n",
      "      ReLU-9          [[1, 512, 7, 7]]      [1, 512, 7, 7]           0       \r\n",
      "     Conv2D-20        [[1, 512, 7, 7]]      [1, 512, 7, 7]       2,359,296   \r\n",
      "  BatchNorm2D-20      [[1, 512, 7, 7]]      [1, 512, 7, 7]         2,048     \r\n",
      "   BasicBlock-8       [[1, 512, 7, 7]]      [1, 512, 7, 7]           0       \r\n",
      "AdaptiveAvgPool2D-1   [[1, 512, 7, 7]]      [1, 512, 1, 1]           0       \r\n",
      "     Linear-1            [[1, 512]]             [1, 4]             2,052     \r\n",
      "===============================================================================\r\n",
      "Total params: 11,188,164\r\n",
      "Trainable params: 11,168,964\r\n",
      "Non-trainable params: 19,200\r\n",
      "-------------------------------------------------------------------------------\r\n",
      "Input size (MB): 0.57\r\n",
      "Forward/backward pass size (MB): 57.04\r\n",
      "Params size (MB): 42.68\r\n",
      "Estimated Total Size (MB): 100.30\r\n",
      "-------------------------------------------------------------------------------\r\n",
      "\r\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'total_params': 11188164, 'trainable_params': 11168964}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 使用 summary 观察网络信息\n",
    "model.summary(input_size=(1, 3, 224, 224), dtype='float32') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# 调用Paddle的VisualDL模块，保存信息到目录中。\n",
    "#log_dir (str) - 输出日志保存的路径。\n",
    "callback = paddle.callbacks.VisualDL(log_dir='visualdl_log_dir')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.6.3  训练配置\n",
    "\n",
    "#### 优化器配置\n",
    "用paddle.Model完成模型的封装后，在训练前，需要对模型进行配置，通过Model.prepare接口来对训练进行提前的配置准备工作，包括设置模型优化器，Loss计算方法，精度计算方法等。\n",
    "\n",
    "<center><img src=\"https://ai-studio-static-online.cdn.bcebos.com/ba86d2cf71b44e2a9ef1f81d58e283d4303c0827fcbe4b558764e12976ec2d91\" width=\"700\" hegiht=\"500\" ></center>\n",
    "<br></br>\n",
    "\n",
    "\n",
    "> - 学习率(learning_rate)参数很重要。\n",
    "> - 如果训练过程中的准确率呈震荡状态，忽大忽小，可以试试把学习率调低"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#通过Model.prepare接口来对训练进行提前的配置准备工作，包括设置模型优化器，Loss计算方法，精度计算方法等\n",
    "# 优化器API文档： https://www.paddlepaddle.org.cn/documentation/docs/zh/api/paddle/optimizer/Overview_cn.html#paddle-optimizer\n",
    "\n",
    "# 学习率衰减策略\n",
    "# 学习率衰减策略 API 文档：https://www.paddlepaddle.org.cn/documentation/docs/zh/api/paddle/optimizer/Overview_cn.html#about-lr\n",
    "scheduler_StepDecay = paddle.optimizer.lr.StepDecay(learning_rate=0.1, step_size=50, gamma=0.9, verbose=False)\n",
    "scheduler_PiecewiseDecay = paddle.optimizer.lr.PiecewiseDecay(boundaries=[100, 1000, 4000, 5000, 6000], values=[0.1, 0.5, 0.01, 0.005], verbose=False)\n",
    "\n",
    "# 尝试使用 SGD、Momentum 方法\n",
    "sgd = paddle.optimizer.SGD(\n",
    "                learning_rate=scheduler_StepDecay, \n",
    "                parameters=model.parameters())\n",
    "\n",
    "\n",
    "adam = paddle.optimizer.Adam( \n",
    "                learning_rate=0.01, #调参\n",
    "                parameters=model.parameters())\n",
    "\n",
    "model.prepare(optimizer= adam, # adam\n",
    "              loss=paddle.nn.CrossEntropyLoss(),\n",
    "              metrics=paddle.metric.Accuracy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 计算资源配置\n",
    "设置该次计算使用的具体计算资源。  \n",
    "首先，可以查看当前使用的计算设备。（此步骤不是必须的）  \n",
    "然后，设置本次训练使用的计算设备。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# 查看当前计算设备\n",
    "device = paddle.device.get_device()\n",
    "print(device)\n",
    "# 使用GPU训练\n",
    "device = paddle.set_device('gpu') # or 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.6.4  训练模型\n",
    "\n",
    "做好模型训练的前期准备工作后，我们正式调用fit()接口来启动训练过程，需要指定以下至少3个关键参数：训练数据集，训练轮次和单次训练数据批次大小。\n",
    "\n",
    "<center><img src=\"https://ai-studio-static-online.cdn.bcebos.com/286c9ba0cdc94c05ac68c2110a423026cca2028ed75645be882d3187024f8863\" width=\"700\" hegiht=\"500\" ></center>\n",
    "<br></br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 训练时间说明：\n",
    "\n",
    "> - 在CPU上运行10个epoch，需要1.5小时左右；\n",
    "> - 在GPU上运行10个epoch，需要30分钟左右；"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss value printed in the log is the current step, and the metric is the average value of previous steps.\r\n",
      "Epoch 1/1\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/layers/utils.py:77: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\r\n",
      "  return (isinstance(seq, collections.Sequence) and\r\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/nn/layer/norm.py:641: UserWarning: When training, we now always track global mean and variance.\r\n",
      "  \"When training, we now always track global mean and variance.\")\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 2904/2904 [==============================] - loss: 0.0549 - acc: 0.5786 - 62ms/step         \r\n",
      "Eval begin...\r\n",
      "step 415/415 [==============================] - loss: 0.0867 - acc: 0.7819 - 23ms/step        \r\n",
      "Eval samples: 830\r\n"
     ]
    }
   ],
   "source": [
    "# fit API文档： https://www.paddlepaddle.org.cn/documentation/docs/zh/api/paddle/Model_cn.html#fit-train-data-none-eval-data-none-batch-size-1-epochs-1-eval-freq-1-log-freq-10-save-dir-none-save-freq-1-verbose-2-drop-last-false-shuffle-true-num-workers-0-callbacks-none\n",
    "\n",
    "# 启动模型训练，指定训练数据集，设置训练轮次，设置每次数据集计算的批次大小，设置日志格式\n",
    "#epochs：总共训练的轮数\n",
    "#batch_size：一个批次的样本数量\n",
    "#如果提示内存不足，可以尝试将batch_size调低\n",
    "#verbose：日志显示，0为不在标准输出流输出日志信息,1为输出进度条记录，2为每个epoch输出一行记录;1为输出进度条记录，2为每个epoch输出一行记录\n",
    "\n",
    "model.fit(train_dataset,\n",
    "          val_dataset,\n",
    "          epochs=1,\n",
    "          batch_size=2,\n",
    "          callbacks=callback,\n",
    "          verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.6.5 模型评估和保存\n",
    "\n",
    "模型训练结束后，我们得到了一个训练好的模型，但是这个模型效果怎么样，还需要我们去具体做下评估。\n",
    "\n",
    "什么是模型评估呢？\n",
    "\n",
    "> - 模型评估其实就是：使用我们预留的测试数据放到所得到的模型中进行实际的预测，并基于标签进行校验，来看模型在测试集上的表现。\n",
    "\n",
    "> - 模型评估的代码实现，在高层API中也非常地简单，我们事先定义好用于评估使用的数据集后，对于训练好的模型进行评估操作可以使用model.evaluate接口；操作结束后会根据prepare接口配置的loss和metric来进行相关指标计算返回。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 本实验评价指标：\n",
    "\n",
    "本次实验，我们采用的评价指标是 <font face=\"黑体\" color=red size=3>准确率（accuracy），简称acc</font>  \n",
    "\n",
    "同学们相互之间比较一下，你的模型评估结果怎么样？你的acc值达到多少了？\n",
    "\n",
    "该实验如果进行了合理的 数据增强，准确率（ accuracy）是可以达到很高的，请大家努力把acc值提升到90%以上。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval begin...\r\n",
      "step 67/67 [==============================] - loss: 0.0052 - acc: 0.7910 - 13ms/step        \r\n",
      "Eval samples: 67\r\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss': [0.0051732725], 'acc': 0.7910447761194029}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#模型评估\n",
    "#对于训练好的模型进行评估操作可以使用 model.evaluate 接口；操作结束后会根据 prepare 接口配置的 loss 和 metric 来进行相关指标计算返回。\n",
    "# 评价指标参考文档：https://www.paddlepaddle.org.cn/documentation/docs/zh/api/paddle/Model_cn.html#evaluate-eval-data-batch-size-1-log-freq-10-verbose-2-num-workers-0-callbacks-none\n",
    "model.evaluate(test_dataset, verbose=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#模型保存\n",
    "model.save('./saved_model/saved_model')  # save for training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.6.6 模型预测\n",
    "\n",
    "以上步骤，我们完成了模型的训练、模型的评估、模型保存；如果这个模型经过评估之后效果不错，那么就可以使用了。我们就可以使用这个保存的模型来进行预测。\n",
    "\n",
    "如何进行模型预测呢？\n",
    "\n",
    "> - 飞桨高层API中提供了model.predict接口来方便用户对训练好的模型进行预测；\n",
    "> - 我们只需要将“预测数据+保存的模型”，放到model.predict接口进行计算即可，接口会把模型计算得到的预测结果返回，从而完成我们的任务。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict begin...\r\n",
      "step 67/67 [==============================] - 12ms/step         \r\n",
      "Predict samples: 67\r\n"
     ]
    }
   ],
   "source": [
    "#预测模型\n",
    "results = model.predict(test_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\r\n",
      "1\r\n",
      "[[ 0.4494054   1.8589294  -2.709025   -0.98785317]]\r\n",
      "[[ 0.80108535  2.0312922  -2.3985271  -1.667168  ]]\r\n",
      "[[-0.487098    2.5169828  -3.8384209   0.09941977]]\r\n",
      "[[ 1.1755923  1.9356494 -2.7956083 -1.824508 ]]\r\n",
      "[[ 0.6587918  1.5227697 -1.9370861 -1.2466118]]\r\n",
      "[[ 1.9423198  1.8514836 -2.0579038 -3.0512297]]\r\n",
      "[[-0.12070499  2.1658874  -3.2705145  -0.2214822 ]]\r\n",
      "[[ 2.30185    1.9300838 -2.6378424 -3.3231502]]\r\n",
      "[[ 1.7931688  1.7564571 -2.713827  -2.3772974]]\r\n",
      "[[ 1.018136   1.9348547 -2.1037087 -2.093875 ]]\r\n",
      "[[ 1.2455556  1.7356219 -2.3573794 -1.9229555]]\r\n",
      "[[ 1.3166553  2.0454793 -2.1393437 -2.5154655]]\r\n",
      "[[ 2.2485528  2.5826378 -2.3228188 -4.113832 ]]\r\n",
      "[[ 0.6856951  1.9657588 -2.340539  -1.5627216]]\r\n",
      "[[ 0.34038985  2.5555618  -3.4037375  -1.1876322 ]]\r\n",
      "[[ 1.7155951  2.2181606 -2.2069125 -3.0874062]]\r\n",
      "[[-0.9589406  2.3568041 -3.914858   0.8861027]]\r\n",
      "[[-2.2687616  3.561953  -6.1434994  2.204158 ]]\r\n",
      "[[-0.8965972   2.812673   -4.498936    0.67248255]]\r\n",
      "[[-1.7266133  3.0567627 -5.3219457  1.823607 ]]\r\n",
      "[[-1.2236824  2.9153998 -5.2624416  1.1972692]]\r\n",
      "[[-1.6313993  2.393093  -4.390437   1.8520648]]\r\n",
      "[[-2.261466   3.1709478 -5.7391357  2.475055 ]]\r\n",
      "[[-2.0998657  2.7529852 -5.1272326  2.396462 ]]\r\n",
      "[[-1.6497151  2.9010382 -5.0573497  1.7648369]]\r\n",
      "[[-2.6754675  2.9362612 -5.56551    2.9678605]]\r\n",
      "[[-1.073315   2.3352654 -4.07773    1.1857122]]\r\n",
      "[[-0.88414484  2.4533503  -4.0443926   0.775055  ]]\r\n",
      "[[-1.7560171  3.3508494 -5.375548   1.4013046]]\r\n",
      "[[-2.615417   4.013784  -6.8865647  2.4297483]]\r\n",
      "[[-1.829337   3.1974657 -5.3266735  1.5116838]]\r\n",
      "[[-1.1488906  2.4435222 -4.151718   1.1106087]]\r\n",
      "[[-2.672726   3.7604275 -6.60363    2.6530373]]\r\n",
      "[[-1.3436769  2.810868  -4.783174   1.3363845]]\r\n",
      "[[-7.1727552 -4.178957   6.645717   1.3258969]]\r\n",
      "[[-10.802859   -8.898961   13.038587    0.8829916]]\r\n",
      "[[-6.100724  -3.6756551  5.3887143  2.429795 ]]\r\n",
      "[[-6.956199  -4.8285522  7.192293   1.4987972]]\r\n",
      "[[-6.806343  -4.737133   7.0949545  1.9803424]]\r\n",
      "[[-10.631139   -8.797351   12.851841    0.9559243]]\r\n",
      "[[-9.890509  -7.7998743 11.965744   1.0906614]]\r\n",
      "[[-6.637445  -4.125729   6.246958   2.3932679]]\r\n",
      "[[-4.850948   -3.7300088   5.50579    -0.28020984]]\r\n",
      "[[-5.89312   -3.9382315  5.5570445  1.115171 ]]\r\n",
      "[[-9.489717  -7.5113807 11.062157   1.4899993]]\r\n",
      "[[-4.060526  -4.7304277  7.44195   -1.7170902]]\r\n",
      "[[-6.123046  -5.145837   7.891695  -0.3783728]]\r\n",
      "[[-6.7471647  -5.1568007   7.3376994  -0.14631017]]\r\n",
      "[[-5.768033  -6.0288777  9.360904  -1.9037125]]\r\n",
      "[[-7.037687  -5.0647235  7.345336   1.0650041]]\r\n",
      "[[-6.3333025 -4.003666   6.096233   2.0686429]]\r\n",
      "[[-8.165305  -4.0971665  5.59594    4.208836 ]]\r\n",
      "[[-6.3591156 -0.0809775 -2.1494312  5.8446784]]\r\n",
      "[[-5.998541  -0.3071279 -1.633659   5.444659 ]]\r\n",
      "[[-5.982375   -0.13737446 -2.0219755   5.588227  ]]\r\n",
      "[[-6.2784123  -0.28474385 -1.8074901   5.720227  ]]\r\n",
      "[[-5.9097333   0.21499354 -2.4844441   5.4800773 ]]\r\n",
      "[[-5.815046    0.34615326 -2.749436    5.516311  ]]\r\n",
      "[[-6.144201    0.20839332 -2.5092714   5.6507225 ]]\r\n",
      "[[-6.217258   -0.11974069 -2.2099724   5.8341565 ]]\r\n",
      "[[-6.0395765   0.08458082 -2.2998967   5.641852  ]]\r\n",
      "[[-6.292765   -0.22815469 -1.8958219   5.7871137 ]]\r\n",
      "[[-5.9349203   0.03097157 -2.209548    5.578063  ]]\r\n",
      "[[-4.8454432  0.6837326 -2.8405902  4.569208 ]]\r\n",
      "[[-5.5436296 -0.4322207 -1.2610528  5.0055714]]\r\n",
      "[[-5.8578863  -0.32924837 -1.6607574   5.3581743 ]]\r\n",
      "[[-5.7073674   0.08094054 -2.3335297   5.431057  ]]\r\n"
     ]
    }
   ],
   "source": [
    "# 观察 result\n",
    "print(type(results)) #list\n",
    "print(len(results)) #len == 1\n",
    "\n",
    "# 一行一行打印结果\n",
    "for i in results[0]:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(shape=[67, 1, 4], dtype=float32, place=CUDAPlace(0), stop_gradient=True,\r\n",
      "       [[[0.18607847, 0.76180643, 0.00790692, 0.04420818]],\r\n",
      "\r\n",
      "        [[0.21990354, 0.75249618, 0.00896723, 0.01863303]],\r\n",
      "\r\n",
      "        [[0.04347746, 0.87683898, 0.00152336, 0.07816018]],\r\n",
      "\r\n",
      "        [[0.31181487, 0.66678441, 0.00587796, 0.01552279]],\r\n",
      "\r\n",
      "        [[0.27809274, 0.65979725, 0.02074026, 0.04136980]],\r\n",
      "\r\n",
      "        [[0.51592660, 0.47112727, 0.00944741, 0.00349878]],\r\n",
      "\r\n",
      "        [[0.08482961, 0.83483732, 0.00363582, 0.07669736]],\r\n",
      "\r\n",
      "        [[0.58813888, 0.40553078, 0.00420919, 0.00212116]],\r\n",
      "\r\n",
      "        [[0.50240386, 0.48429418, 0.00554229, 0.00775965]],\r\n",
      "\r\n",
      "        [[0.27857813, 0.69674349, 0.01227855, 0.01239989]],\r\n",
      "\r\n",
      "        [[0.37013263, 0.60421354, 0.01008376, 0.01557007]],\r\n",
      "\r\n",
      "        [[0.31991184, 0.66306269, 0.01009506, 0.00693045]],\r\n",
      "\r\n",
      "        [[0.41515639, 0.57983309, 0.00429428, 0.00071625]],\r\n",
      "\r\n",
      "        [[0.21048497, 0.75708681, 0.01020809, 0.02222010]],\r\n",
      "\r\n",
      "        [[0.09612054, 0.88075089, 0.00227385, 0.02085473]],\r\n",
      "\r\n",
      "        [[0.37300166, 0.61655551, 0.00738223, 0.00306051]],\r\n",
      "\r\n",
      "        [[0.02863417, 0.78866822, 0.00148986, 0.18120776]],\r\n",
      "\r\n",
      "        [[0.00232973, 0.79350960, 0.00004836, 0.20411235]],\r\n",
      "\r\n",
      "        [[0.02143462, 0.87504727, 0.00058431, 0.10293392]],\r\n",
      "\r\n",
      "        [[0.00643685, 0.76924914, 0.00017670, 0.22413737]],\r\n",
      "\r\n",
      "        [[0.01332989, 0.83638644, 0.00023486, 0.15004875]],\r\n",
      "\r\n",
      "        [[0.01116226, 0.62454951, 0.00070716, 0.36358106]],\r\n",
      "\r\n",
      "        [[0.00290894, 0.66527551, 0.00008983, 0.33172569]],\r\n",
      "\r\n",
      "        [[0.00456953, 0.58538061, 0.00022136, 0.40982854]],\r\n",
      "\r\n",
      "        [[0.00792769, 0.75078166, 0.00026256, 0.24102813]],\r\n",
      "\r\n",
      "        [[0.00179510, 0.49116838, 0.00009976, 0.50693673]],\r\n",
      "\r\n",
      "        [[0.02448242, 0.73991507, 0.00121354, 0.23438902]],\r\n",
      "\r\n",
      "        [[0.02903091, 0.81717736, 0.00123135, 0.15256041]],\r\n",
      "\r\n",
      "        [[0.00527186, 0.87065840, 0.00014126, 0.12392850]],\r\n",
      "\r\n",
      "        [[0.00109510, 0.82885396, 0.00001529, 0.17003568]],\r\n",
      "\r\n",
      "        [[0.00550288, 0.83888549, 0.00016662, 0.15544505]],\r\n",
      "\r\n",
      "        [[0.02129946, 0.77363062, 0.00105744, 0.20401244]],\r\n",
      "\r\n",
      "        [[0.00120668, 0.75071740, 0.00002368, 0.24805219]],\r\n",
      "\r\n",
      "        [[0.01260382, 0.80315262, 0.00040434, 0.18383917]],\r\n",
      "\r\n",
      "        [[0.00000099, 0.00001980, 0.99510950, 0.00486970]],\r\n",
      "\r\n",
      "        [[0.00000000, 0.00000000, 0.99999475, 0.00000526]],\r\n",
      "\r\n",
      "        [[0.00000973, 0.00011000, 0.95056945, 0.04931074]],\r\n",
      "\r\n",
      "        [[0.00000071, 0.00000600, 0.99663687, 0.00335647]],\r\n",
      "\r\n",
      "        [[0.00000091, 0.00000722, 0.99401951, 0.00597238]],\r\n",
      "\r\n",
      "        [[0.00000000, 0.00000000, 0.99999321, 0.00000682]],\r\n",
      "\r\n",
      "        [[0.00000000, 0.00000000, 0.99998105, 0.00001892]],\r\n",
      "\r\n",
      "        [[0.00000248, 0.00003062, 0.97920632, 0.02076050]],\r\n",
      "\r\n",
      "        [[0.00003168, 0.00009718, 0.99681073, 0.00306045]],\r\n",
      "\r\n",
      "        [[0.00001052, 0.00007432, 0.98827934, 0.01163586]],\r\n",
      "\r\n",
      "        [[0.00000000, 0.00000001, 0.99993038, 0.00006964]],\r\n",
      "\r\n",
      "        [[0.00001010, 0.00000517, 0.99987948, 0.00010525]],\r\n",
      "\r\n",
      "        [[0.00000082, 0.00000218, 0.99974102, 0.00025600]],\r\n",
      "\r\n",
      "        [[0.00000076, 0.00000375, 0.99943382, 0.00056168]],\r\n",
      "\r\n",
      "        [[0.00000027, 0.00000021, 0.99998665, 0.00001282]],\r\n",
      "\r\n",
      "        [[0.00000057, 0.00000407, 0.99812609, 0.00186927]],\r\n",
      "\r\n",
      "        [[0.00000393, 0.00004036, 0.98245114, 0.01750455]],\r\n",
      "\r\n",
      "        [[0.00000084, 0.00004937, 0.80008936, 0.19986045]],\r\n",
      "\r\n",
      "        [[0.00000500, 0.00266204, 0.00033643, 0.99699652]],\r\n",
      "\r\n",
      "        [[0.00001068, 0.00316434, 0.00083980, 0.99598515]],\r\n",
      "\r\n",
      "        [[0.00000940, 0.00324916, 0.00049351, 0.99624795]],\r\n",
      "\r\n",
      "        [[0.00000613, 0.00245906, 0.00053635, 0.99699843]],\r\n",
      "\r\n",
      "        [[0.00001125, 0.00514054, 0.00034567, 0.99450254]],\r\n",
      "\r\n",
      "        [[0.00001192, 0.00565004, 0.00025565, 0.99408239]],\r\n",
      "\r\n",
      "        [[0.00000751, 0.00430946, 0.00028455, 0.99539846]],\r\n",
      "\r\n",
      "        [[0.00000582, 0.00258814, 0.00032005, 0.99708599]],\r\n",
      "\r\n",
      "        [[0.00000841, 0.00384306, 0.00035409, 0.99579442]],\r\n",
      "\r\n",
      "        [[0.00000566, 0.00243412, 0.00045929, 0.99710089]],\r\n",
      "\r\n",
      "        [[0.00000996, 0.00388200, 0.00041306, 0.99569499]],\r\n",
      "\r\n",
      "        [[0.00007983, 0.02011120, 0.00059271, 0.97921628]],\r\n",
      "\r\n",
      "        [[0.00002605, 0.00432196, 0.00188679, 0.99376523]],\r\n",
      "\r\n",
      "        [[0.00001340, 0.00337382, 0.00089095, 0.99572182]],\r\n",
      "\r\n",
      "        [[0.00001447, 0.00472310, 0.00042231, 0.99484009]]])\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/tensor/creation.py:125: DeprecationWarning: `np.object` is a deprecated alias for the builtin `object`. To silence this warning, use `object` by itself. Doing this will not modify any behavior and is safe. \r\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\r\n",
      "  if data.dtype == np.object:\r\n"
     ]
    }
   ],
   "source": [
    "# 将结果用 softmax 处理后变成概率值\n",
    "x = paddle.to_tensor(results[0])\n",
    "m = paddle.nn.Softmax()\n",
    "out = m(x)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "为了观察预测结果，我们还需要把标签转换一下：\n",
    "\n",
    "<center><img src=\"https://ai-studio-static-online.cdn.bcebos.com/5482fbfb24a349ac902c378f2014017feb24fe2faf9242deb6e51b0bbd8ae709\" width=\"700\" hegiht=\"500\" ></center>\n",
    "<br></br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#用一个字典，指名标签对应的数值\n",
    "label_dic = {}\n",
    "for i, label in enumerate(labels):\n",
    "    label_dic[i] = label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#预测标签结果写入predict_labels\n",
    "predict_labels = []\n",
    "#依次取results[0]中的每个图片的预测数组\n",
    "for result in results[0]: \n",
    "    #np.argmax:返回一个numpy数组中的最大值的索引\n",
    "    #注意：索引是标签，不是返回数据的最大值\n",
    "    lab_index = np.argmax(result)\n",
    "    lab = label_dic[lab_index]\n",
    "    predict_labels.append(lab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['M2', 'M2', 'M2', 'M2', 'M2', 'B1', 'M2', 'B1', 'B1', 'M2', 'M2', 'M2', 'M2', 'M2', 'M2', 'M2', 'M2', 'M2', 'M2', 'M2', 'M2', 'M2', 'M2', 'M2', 'M2', 'S3', 'M2', 'M2', 'M2', 'M2', 'M2', 'M2', 'M2', 'M2', 'R0', 'R0', 'R0', 'R0', 'R0', 'R0', 'R0', 'R0', 'R0', 'R0', 'R0', 'R0', 'R0', 'R0', 'R0', 'R0', 'R0', 'R0', 'S3', 'S3', 'S3', 'S3', 'S3', 'S3', 'S3', 'S3', 'S3', 'S3', 'S3', 'S3', 'S3', 'S3', 'S3']\r\n"
     ]
    }
   ],
   "source": [
    "#看一下预测结果\n",
    "print(predict_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "为了更直观的观察预测效果，我们生成一个result.csv文件，把预测的结果列在这个csv文件里，运行下面这段代码，就会在当前目录下生成一个result.csv文件。\n",
    "\n",
    "打开result.csv文件，我们可以看到结果：\n",
    "\n",
    "<center><img src=\"https://ai-studio-static-online.cdn.bcebos.com/e3750e1ee73244ff92c46a831df3c8caba2c42d3e83549ab9e7674b96fd635c8\" width=\"500\" hegiht=\"500\" ></center>\n",
    "<br></br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "final_result = [ ]\n",
    "file_name_test = train_parameters['test_list_dir'] \n",
    "f = open(file_name_test, 'r') \n",
    "#按行读取数据\n",
    "data = f.readlines()\n",
    "for i in range(len(data)):\n",
    "    #将每行数据按照空格分割成2部分，并取第一部分的路径名和图像文件名，例如:R0/1.png\n",
    "    img_path = data[i].split('\\t')[0]\n",
    "    final_result.append(img_path + ',' + str(predict_labels[i]) + '\\n')\n",
    "\n",
    "f.close( )\n",
    "\n",
    "with open('result.csv',\"w\") as f: \n",
    "    f.writelines(final_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.总结\n",
    "\n",
    " 本次实验，我们用paddlepaddle（飞桨）深度学习框架 搭建了一个 图像分类模型，完成了桃子的分类任务。  \n",
    " \n",
    " 通过本次实验，我们学习了：\n",
    " \n",
    "> - paddlepaddle深度学习框架的使用方法；\n",
    "> - 如何用paddlepaddle深度学习框架搭建 桃子分类模型；\n",
    "> - 如何完成模型的训练、评估、保存、预测等深度学习工作过程；\n",
    "\n",
    "图像分类任务是计算机视觉（CV）领域的基础性任务，虽然难度不大，但是却很重要，是其他计算机视觉任务的基石。我们一定要多动手，多调试代码，增加熟练程度，为更复杂的深度学习项目打下基础。\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
