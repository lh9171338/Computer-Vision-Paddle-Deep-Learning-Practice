{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **一、任务介绍**\n",
    "\n",
    "**手写数字识别**（handwritten numeral recognition）是光学字符识别技术（optical character recognition，OCR）的一个分支，是初级研究者的入门基础，在现实产业中也占据着十分重要的地位，它主要的研究内容是如何利用电子计算机和图像分类技术自动识别人手写在纸张上的阿拉伯数字（0～9）。因此，本实验任务简易描述如图所示：  ![](https://ai-studio-static-online.cdn.bcebos.com/4c7206c4ba444963981b43118627fcbf1e67f94840d144bfb7b00265cf63dcfd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **二、模型原理**\n",
    "\n",
    "\t近年来，神经网络模型一直层出不穷，在各个计算机视觉任务中都呈现百花齐放的态势。为了让开发者更清楚地了解网络模型的搭建过程，以及为了在后续的各项视觉子任务实战中奠定基础。下面本节将以MNIST手写数字识别为例，在PaddlePaddle深度学习开发平台下构建一个LeNet网络模型并进行详细说明。\n",
    "\n",
    "\tLeNet是第一个将卷积神经网络推上计算机视觉舞台的算法模型，它由LeCun在1998年提出。在早期应用于手写数字图像识别任务。该模型采用顺序结构，主要包括7层（2个卷积层、2个池化层和3个全连接层），卷积层和池化层交替排列。以mnist手写数字分类为例构建一个LeNet-5模型。每个手写数字图片样本的宽与高均为28像素，样本标签值是0~9，代表0至9十个数字。\n",
    "**下面详细解析LeNet-5模型的网络结构及原理**\n",
    "\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/c758063e28754e20ac3ec70cef5ca1b0168ad923000d47f1bd686b59d2f3c23b)\n",
    "\n",
    "图1 LeNet-5整体网络模型\n",
    "\n",
    "\n",
    "（1）卷积层L1\n",
    "\n",
    "L1层的输入数据形状大小为$\\mathbb{R}^{m \\times 1 \\times 28 \\times 28}$，表示样本批量为m，通道数量为1，行与列的大小都为28。L1层的输出数据形状大小为$\\mathbb{R}^{m \\times 6 \\times 24 \\times 24}$，表示样本批量为m，通道数量为6，行与列维都为24。\n",
    "\n",
    "这里有两个问题很关键：一是，为什么通道数从1变成了6呢？原因是模型的卷积层L1设定了6个卷积核，每个卷积核都与输入数据发生运算，最终分别得到6组数据。二是，为什么行列大小从28变成了24呢？原因是每个卷积核的行维与列维都为5，卷积核（5×5）在输入数据（28×28）上移动，且每次移动步长为1，那么输出数据的行列大小分别为28-5+1=24。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "        # #卷积层L1 \n",
    "        # self.conv1 = paddle.nn.Conv2D(in_channels=1,\n",
    "        #                               out_channels=6,\n",
    "        #                               kernel_size=5,\n",
    "        #                               stride=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "（2）池化层L2\n",
    "\n",
    "L2层的输入数据形状大小为$\\mathbb{R}^{m \\times 6 \\times 24 \\times 24}$，表示样本批量为m，通道数量为6，行与列的大小都为24。L2层的输出数据形状大小为$\\mathbb{R}^{m \\times 6 \\times 12 \\times 12}$，表示样本批量为m，通道数量为6，行与列维都为12。\n",
    "\n",
    "在这里，为什么行列大小从24变成了12呢？原因是池化层中的过滤器形状大小为2×2，其在输入数据（24×24）上移动，且每次移动步长（跨距）为2，每次选择4个数（2×2）中最大值作为输出，那么输出数据的行列大小分别为24÷2=12。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "        # #池化层L2\n",
    "        # self.pool1 = paddle.nn.MaxPool2D(kernel_size=2,\n",
    "        #                                  stride=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "（3）卷积层L3\n",
    "\n",
    "L3层的输入数据形状大小为$\\mathbb{R}^{m \\times 6 \\times 12 \\times 12}$，表示样本批量为m，通道数量为6，行与列的大小都为12。L3层的输出数据形状大小为$\\mathbb{R}^{m \\times 16 \\times 8 \\times 8}$，表示样本批量为m，通道数量为16，行与列维都为8。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "        # #卷积层L3\n",
    "        # self.conv2 = paddle.nn.Conv2D(in_channels=6,\n",
    "        #                               out_channels=16,\n",
    "        #                               kernel_size=5,\n",
    "        #                               stride=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "（4）池化层L4\n",
    "\n",
    "L4层的输入数据形状大小为$\\mathbb{R}^{m \\times 16 \\times 8 \\times 8}$，表示样本批量为m，通道数量为16，行与列的大小都为8。L4层的输出数据形状大小为$\\mathbb{R}^{m \\times 16 \\times 4 \\times 4}$，表示样本批量为m，通道数量为16，行与列维都为4。池化层L4中的过滤器形状大小为2×2，其在输入数据（形状大小24×24）上移动，且每次移动步长（跨距）为2，每次选择4个数（形状大小2×2）中最大值作为输出。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "        # #池化层L4\n",
    "        # self.pool2 = paddle.nn.MaxPool2D(kernel_size=2,\n",
    "        #                                  stride=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "（5）线性层L5\n",
    "\n",
    "L5层输入数据形状大小为$\\mathbb{R}^{m \\times 256}$，表示样本批量为m，输入特征数量为256。输出数据形状大小为$\\mathbb{R}^{m \\times 120}$，表示样本批量为m，输出特征数量为120。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "        # #线性层L5\n",
    "        # self.fc1=paddle.nn.Linear(256,120)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "（6）线性层L6\n",
    "\n",
    "L6层的输入数据形状大小为$\\mathbb{R}^{m \\times 120}$，表示样本批量为m，输入特征数量为120。L6层的输出数据形状大小为$\\mathbb{R}^{m \\times 84}$，表示样本批量为m，输出特征数量为84。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "        # #线性层L6\n",
    "        # self.fc2=paddle.nn.Linear(120,84)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "（7）线性层L7\n",
    "\n",
    "L7层的输入数据形状大小为$\\mathbb{R}^{m \\times 84}$，表示样本批量为m，输入特征数量为84。L7层的输出数据形状大小为$\\mathbb{R}^{m \\times 10}$，表示样本批量为m，输出特征数量为10。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "        # #线性层L7\n",
    "        # self.fc3=paddle.nn.Linear(84,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **三、MNIST数据集**\n",
    "\n",
    "## 3.1 数据集介绍\n",
    "\n",
    "手写数字分类数据集来源MNIST数据集，该数据集可以公开免费获取。该数据集中的训练集样本数量为60000个，测试集样本数量为10000个。每个样本均是由28×28像素组成的矩阵，每个像素点的值是标量，取值范围在0至255之间，可以认为该数据集的颜色通道数为1。数据分为图片和标签，图片是28*28的像素矩阵，标签为0~9共10个数字。\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/fc73217ae57f451a89badc801a903bb742e42eabd9434ecc8089efe19a66c076)\n",
    "\n",
    "## 3.2 数据读取\n",
    "(1)transform函数是对数据进行归一化和标准化\n",
    "\n",
    "(2)train_dataset和test_dataset\n",
    "\n",
    "paddle.vision.datasets.MNIST()中的mode='train'和mode='test'分别用于获取mnist训练集和测试集\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-09-11T05:59:03.246403Z",
     "iopub.status.busy": "2023-09-11T05:59:03.245879Z",
     "iopub.status.idle": "2023-09-11T05:59:14.464288Z",
     "shell.execute_reply": "2023-09-11T05:59:14.463197Z",
     "shell.execute_reply.started": "2023-09-11T05:59:03.246373Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/matplotlib/__init__.py:107: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\r\n",
      "  from collections import MutableMapping\r\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/matplotlib/rcsetup.py:20: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\r\n",
      "  from collections import Iterable, Mapping\r\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/matplotlib/colors.py:53: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\r\n",
      "  from collections import Sized\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "下载并加载训练数据\r\n",
      "item  119/2421 [>.............................] - ETA: 2s - 889us/item"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cache file /home/aistudio/.cache/paddle/dataset/mnist/train-images-idx3-ubyte.gz not found, downloading https://dataset.bj.bcebos.com/mnist/train-images-idx3-ubyte.gz \r\n",
      "Begin to download\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "item 8/8 [============================>.] - ETA: 0s - 2ms/item"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Download finished\r\n",
      "Cache file /home/aistudio/.cache/paddle/dataset/mnist/train-labels-idx1-ubyte.gz not found, downloading https://dataset.bj.bcebos.com/mnist/train-labels-idx1-ubyte.gz \r\n",
      "Begin to download\r\n",
      "\r\n",
      "Download finished\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "item 115/403 [=======>......................] - ETA: 0s - 1ms/item"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cache file /home/aistudio/.cache/paddle/dataset/mnist/t10k-images-idx3-ubyte.gz not found, downloading https://dataset.bj.bcebos.com/mnist/t10k-images-idx3-ubyte.gz \r\n",
      "Begin to download\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "item 2/2 [===========================>..] - ETA: 0s - 2ms/item"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Download finished\r\n",
      "Cache file /home/aistudio/.cache/paddle/dataset/mnist/t10k-labels-idx1-ubyte.gz not found, downloading https://dataset.bj.bcebos.com/mnist/t10k-labels-idx1-ubyte.gz \r\n",
      "Begin to download\r\n",
      "\r\n",
      "Download finished\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "加载完成\r\n"
     ]
    }
   ],
   "source": [
    "#导入数据集Compose的作用是将用于数据集预处理的接口以列表的方式进行组合。\n",
    "#导入数据集Normalize的作用是图像归一化处理，支持两种方式： 1. 用统一的均值和标准差值对图像的每个通道进行归一化处理； 2. 对每个通道指定不同的均值和标准差值进行归一化处理。\n",
    "import paddle\n",
    "from paddle.vision.transforms import Compose, Normalize\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "transform = Compose([Normalize(mean=[127.5],std=[127.5],data_format='CHW')])\n",
    "# 使用transform对数据集做归一化\n",
    "print('下载并加载训练数据')\n",
    "train_dataset = paddle.vision.datasets.MNIST(mode='train', transform=transform)\n",
    "val_dataset = paddle.vision.datasets.MNIST(mode='test', transform=transform)\n",
    "print('加载完成')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**让我们一起看看数据集中的图片是什么样子的**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-09-11T05:59:29.320522Z",
     "iopub.status.busy": "2023-09-11T05:59:29.319326Z",
     "iopub.status.idle": "2023-09-11T05:59:29.709547Z",
     "shell.execute_reply": "2023-09-11T05:59:29.708572Z",
     "shell.execute_reply.started": "2023-09-11T05:59:29.320488Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_data0, train_label_0 = train_dataset[0][0],train_dataset[0][1]\n",
    "train_data0 = train_data0.reshape([28,28])\n",
    "plt.figure(figsize=(2,2))\n",
    "print(plt.imshow(train_data0, cmap=plt.cm.binary))\n",
    "print('train_data0 的标签为: ' + str(train_label_0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "让我们再来看看数据样子是什么样的吧"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(train_data0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **四、LeNet模型搭建**\n",
    "**构建LeNet-5模型进行MNIST手写数字分类**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#导入需要的包\n",
    "import paddle\n",
    "import paddle.nn.functional as F\n",
    "from paddle.vision.transforms import Compose, Normalize\n",
    "\n",
    "#定义模型\n",
    "class LeNetModel(paddle.nn.Layer):\n",
    "    def __init__(self):\n",
    "        super(LeNetModel, self).__init__()\n",
    "        # 创建卷积和池化层块，每个卷积层后面接着2x2的池化层\n",
    "        #卷积层L1\n",
    "        self.conv1 = paddle.nn.Conv2D(in_channels=1,\n",
    "                                      out_channels=6,\n",
    "                                      kernel_size=5,\n",
    "                                      stride=1)\n",
    "        #池化层L2\n",
    "        self.pool1 = paddle.nn.MaxPool2D(kernel_size=2,\n",
    "                                         stride=2)\n",
    "        #卷积层L3\n",
    "        self.conv2 = paddle.nn.Conv2D(in_channels=6,\n",
    "                                      out_channels=16,\n",
    "                                      kernel_size=5,\n",
    "                                      stride=1)\n",
    "        #池化层L4\n",
    "        self.pool2 = paddle.nn.MaxPool2D(kernel_size=2,\n",
    "                                         stride=2)\n",
    "        #线性层L5\n",
    "        self.fc1=paddle.nn.Linear(256,120)\n",
    "        #线性层L6\n",
    "        self.fc2=paddle.nn.Linear(120,84)\n",
    "        #线性层L7\n",
    "        self.fc3=paddle.nn.Linear(84,10)\n",
    "\n",
    "    #正向传播过程\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.sigmoid(x)\n",
    "        x = self.pool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.sigmoid(x)\n",
    "        x = self.pool2(x)\n",
    "        x = paddle.flatten(x, start_axis=1,stop_axis=-1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.sigmoid(x)\n",
    "        x = self.fc2(x)\n",
    "        x = F.sigmoid(x)\n",
    "        out = self.fc3(x)\n",
    "        return out\n",
    "\n",
    "model=paddle.Model(LeNetModel())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **五、模型优化过程**\n",
    "\n",
    "## 5.1 损失函数\n",
    "**由于是分类问题，我们选择交叉熵损失函数。交叉熵主要用于衡量估计值与真实值之间的差距。交叉熵值越小，模型预测效果越好。***\n",
    "\n",
    "$E(\\mathbf{y}^{i},\\mathbf{\\hat{y}}^{i})=-\\sum_{j=1}^{q}\\mathbf{y}_{j}^{i}ln(\\mathbf{\\hat{y}}_{j}^{i})$\n",
    "\n",
    "其中，$\\mathbf{y}^{i} \\in \\mathbb{R}^{q}$为真实值，$y_{j}^{i}$是$\\mathbf{y}^{i}$中的元素(取值为0或1)，$j=1,...,q$。$\\mathbf{\\hat{y}^{i}} \\in \\mathbb{R}^{q}$是预测值（样本在每个类别上的概率）。其中，在paddle里面交叉熵损失对应的API是paddle.nn.CrossEntropyLoss()\n",
    "\n",
    "## 5.2 参数优化\n",
    "定义好了正向传播过程之后，接着随机化初始参数，然后便可以计算出每层的结果，每次将得到m×10的矩阵作为预测结果，其中m是小批量样本数。接下来进行反向传播过程，预测结果与真实结果之间肯定存在差异，以缩减该差异作为目标，计算模型参数梯度。进行多轮迭代，便可以优化模型，使得预测结果与真实结果之间更加接近。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **六、模型训练与评估**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**训练配置：设定训练超参数**\n",
    "\n",
    "1、批大小batch_size设置为64，表示每次输入64张图片；\n",
    "\n",
    "2、迭代次数epoch设置为5，表示训练5轮；\n",
    "\n",
    "3、日志显示verbose=1，表示带进度条的输出日志信息。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss value printed in the log is the current step, and the metric is the average value of previous step.\r\n",
      "Epoch 1/5\r\n",
      "step  10/938 [..............................] - loss: 2.3076 - acc: 0.1062 - ETA: 21s - 23ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/layers/utils.py:77: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\r\n",
      "  return (isinstance(seq, collections.Sequence) and\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step  20/938 [..............................] - loss: 2.3023 - acc: 0.1023 - ETA: 18s - 20ms/stepstep 938/938 [==============================] - loss: 0.1927 - acc: 0.7765 - 16ms/step         \r\n",
      "Epoch 2/5\r\n",
      "step 938/938 [==============================] - loss: 0.0913 - acc: 0.9584 - 17ms/step        \r\n",
      "Epoch 3/5\r\n",
      "step 938/938 [==============================] - loss: 0.0232 - acc: 0.9700 - 17ms/step         \r\n",
      "Epoch 4/5\r\n",
      "step 938/938 [==============================] - loss: 0.0057 - acc: 0.9763 - 18ms/step        \r\n",
      "Epoch 5/5\r\n",
      "step 938/938 [==============================] - loss: 0.0907 - acc: 0.9798 - 17ms/step         \r\n",
      "Eval begin...\r\n",
      "The loss value printed in the log is the current batch, and the metric is the average value of previous step.\r\n",
      "step 10000/10000 [==============================] - loss: 7.5607e-04 - acc: 0.9794 - 2ms/step         \r\n",
      "Eval samples: 10000\r\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss': [0.00075607264], 'acc': 0.9794}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.prepare(paddle.optimizer.Adam(parameters=model.parameters()),\n",
    "              paddle.nn.CrossEntropyLoss(),\n",
    "              paddle.metric.Accuracy())\n",
    "\n",
    "model.fit(train_dataset,\n",
    "          epochs=5,\n",
    "          batch_size=64,\n",
    "          verbose=1)\n",
    "\n",
    "model.evaluate(val_dataset,verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "经过5个epoch世代迭代，LeNet5模型在MNIST图像分类任务上的准确度达到98%左右。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **七、模型可视化**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------\r\n",
      " Layer (type)       Input Shape          Output Shape         Param #    \r\n",
      "===========================================================================\r\n",
      "   Conv2D-1       [[1, 1, 28, 28]]      [1, 6, 24, 24]          156      \r\n",
      "  MaxPool2D-1     [[1, 6, 24, 24]]      [1, 6, 12, 12]           0       \r\n",
      "   Conv2D-2       [[1, 6, 12, 12]]      [1, 16, 8, 8]          2,416     \r\n",
      "  MaxPool2D-2     [[1, 16, 8, 8]]       [1, 16, 4, 4]            0       \r\n",
      "   Linear-1          [[1, 256]]            [1, 120]           30,840     \r\n",
      "   Linear-2          [[1, 120]]            [1, 84]            10,164     \r\n",
      "   Linear-3          [[1, 84]]             [1, 10]              850      \r\n",
      "===========================================================================\r\n",
      "Total params: 44,426\r\n",
      "Trainable params: 44,426\r\n",
      "Non-trainable params: 0\r\n",
      "---------------------------------------------------------------------------\r\n",
      "Input size (MB): 0.00\r\n",
      "Forward/backward pass size (MB): 0.04\r\n",
      "Params size (MB): 0.17\r\n",
      "Estimated Total Size (MB): 0.22\r\n",
      "---------------------------------------------------------------------------\r\n",
      "\r\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'total_params': 44426, 'trainable_params': 44426}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.summary((1,1,28,28))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "请点击[此处](https://ai.baidu.com/docs#/AIStudio_Project_Notebook/a38e5576)查看本环境基本用法.  <br>\n",
    "Please click [here ](https://ai.baidu.com/docs#/AIStudio_Project_Notebook/a38e5576) for more detailed instructions. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
